{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7418bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df4526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStatmuseUrl(playerName): \n",
    "    \"\"\"Generate StatMuse URL using the name directly from Excel\"\"\"\n",
    "    if pd.isna(playerName):\n",
    "        return None\n",
    "    nameForUrl = playerName.strip().lower().replace(' ', '-')\n",
    "    return f\"https://www.statmuse.com/nfl/ask/{nameForUrl}-stats-career\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c82cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getPlayerGames(playerName):\n",
    "    url = generateStatmuseUrl(playerName)\n",
    "    if not url:\n",
    "        return 0, None, \"No valid URL\"\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
    "    } # act as a browser to nbot get blocked\n",
    "    #https://www.zenrows.com/blog/user-agent-web-scraping#how-to\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser') \n",
    "            for table in soup.find_all('table'):\n",
    "                trs = table.find_all('tr')\n",
    "                if trs:\n",
    "                    lastTr = trs[-1] #Career stats were always last here\n",
    "                    tds = lastTr.find_all('td')\n",
    "                    for i, td in enumerate(tds): #enumerate to get index\n",
    "                        text = td.get_text(strip=True)\n",
    "                        if text.isdigit():\n",
    "                            num = int(text) \n",
    "                            if 0 <= num <= 400 and i <= 8: # most games ever played isless than 400\n",
    "                                return num, url, \"yippee!!!!!!!\"\n",
    "            return 0, url, \"No games\"\n",
    "        else:\n",
    "            return 0, url, f\"HTTP {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return 0, url, f\"Error: {str(e)}\"\n",
    "    return 0, url, \"Unknown Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5703447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCsvWithGames(inputPath, outputPath=None, startFrom=0): #put all results into column in csv\n",
    "    print(f\"Reading CSV from: {inputPath}\")\n",
    "    df = pd.read_csv(inputPath)\n",
    "    print(f\"Total players in CSV: {len(df)}\")\n",
    "\n",
    "    for col in ['statmuse_url', 'games_played', 'scrape_status']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = '' if col != 'games_played' else 0 # create the column\n",
    "\n",
    "    if outputPath is None:\n",
    "        outputPath = inputPath.replace('.csv', '_with_games.csv') #create new output\n",
    "\n",
    "    successful, failed, skipped = 0, 0, 0\n",
    "\n",
    "    print(\"==========\" )\n",
    "\n",
    "    for idx in range(startFrom, len(df)):\n",
    "        playerName = df.at[idx, 'nameFull']\n",
    "        if pd.notna(df.at[idx, 'games_played']) and df.at[idx, 'scrape_status'] == 'yippee!!!!!!!':\n",
    "            skipped += 1\n",
    "            print(f\"[{idx + 1}/{len(df)}] Skipping {playerName} - already processed\")\n",
    "            continue\n",
    "\n",
    "        if pd.isna(playerName):\n",
    "            df.at[idx, 'scrape_status'] = 'No name'\n",
    "            failed += 1\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing: {playerName}\")\n",
    "        games, url, status = getPlayerGames(playerName)\n",
    "        df.at[idx, 'statmuse_url'] = url or ''\n",
    "        df.at[idx, 'games_played'] = games\n",
    "        df.at[idx, 'scrape_status'] = status\n",
    "\n",
    "        if status == 'yippee!!!!!!!':\n",
    "            successful += 1\n",
    "            print(f\"  Found: {games} games\")\n",
    "        else:\n",
    "            failed += 1\n",
    "            print(f\"  Failed: {status}\")\n",
    "\n",
    "        if (idx - startFrom + 1) % 25 == 0: # saves progress incase power goes out\n",
    "            df.to_csv(outputPath, index=False)\n",
    "            rate = successful / (successful + failed) * 100 if (successful + failed) else 0\n",
    "            print(f\" Progress saved. Success rate: {rate:.2f}% \")\n",
    "\n",
    "        if idx < len(df) - 1: # pause after each player so no rate limiting\n",
    "            time.sleep(4)\n",
    "\n",
    "        if status == \"Rate limited\" and failed > 10 and successful == 0:\n",
    "            print(\"Too many rate limit errors. Stopping to avoid blocking.\")\n",
    "            break\n",
    "\n",
    "    df.to_csv(outputPath, index=False)\n",
    "\n",
    "    print(\"==========\" )    \n",
    "    print(\"WE DONE\")\n",
    "    print(\"==========\" ) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c65019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFL Player Games Scraper (CamelCase Version)\n",
      "============================================================\n",
      "Reading CSV from: C:\\Users\\Colin\\Desktop\\NFLProject\\draftAndCombine.csv\n",
      "Total players in CSV: 3911\n",
      "==========\n",
      "Processing: Darnell Alford\n",
      "  Found: 5 games\n",
      "Processing: Rashard Anderson\n",
      "  Found: 27 games\n",
      "Processing: Reggie Austin\n",
      "  Found: 18 games\n",
      "Processing: Mark Baniewicz\n",
      "  Found: 3 games\n",
      "Processing: Rashidi Barnes\n",
      "  Found: 1 games\n",
      "Processing: David Barrett\n",
      "  Found: 131 games\n",
      "Processing: William Bartee\n",
      "  Found: 87 games\n",
      "Processing: Robert Bean\n",
      "  Found: 32 games\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inputCsv = r\"\\draftAndCombine.csv\"\n",
    "    outputCsv = r\"\\draftAndCombineAndGames.csv\"\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    processCsvWithGames(inputCsv, outputCsv)\n",
    "    # resumeProcessing(inputCsv, outputCsv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
